{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ3rN2JBajqB0Vc7lE88OF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauromelo-ti-ifce/PPGCC/blob/main/n1_am.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2n_dmQXAZ-DS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WAV_uv1sYtlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import csv\n",
        "import random\n",
        "import math\n",
        "import operator\n",
        "\n",
        "def loadDataset(iris, split, trainingSet=[] , testSet=[]):\n",
        "    with open(iris, 'r') as csvfile:\n",
        "        lines = csv.reader(csvfile)\n",
        "        dataset = list(lines)\n",
        "        for x in range(len(dataset)-1):\n",
        "            for y in range(4):\n",
        "                dataset[x][y] = float(dataset[x][y])\n",
        "            if random.random() < split:\n",
        "                trainingSet.append(dataset[x])\n",
        "            else:\n",
        "                testSet.append(dataset[x])\n",
        "\n",
        "def euclideanDistance(instance1, instance2, length):\n",
        "    distance = 0\n",
        "    for x in range(length):\n",
        "        distance += pow((instance1[x] - instance2[x]), 2)\n",
        "    return math.sqrt(distance)\n",
        "\n",
        " def getNeighbors(trainingSet, testInstance, k):\n",
        "    distances = []\n",
        "    length = len(testInstance)-1\n",
        "    for x in range(len(trainingSet)):\n",
        "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
        "        distances.append((trainingSet[x], dist))\n",
        "    distances.sort(key=operator.itemgetter(1))\n",
        "    neighbors = []\n",
        "    for x in range(k):\n",
        "        neighbors.append(distances[x][0])\n",
        "    return neighbors\n",
        "\n",
        "def getResponse(neighbors):\n",
        "    classVotes = {}\n",
        "    for x in range(len(neighbors)):\n",
        "        response = neighbors[x][-1]\n",
        "        if response in classVotes:\n",
        "            classVotes[response] += 1\n",
        "        else:\n",
        "            classVotes[response] = 1\n",
        "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    return sortedVotes[0][0]\n",
        "\n",
        "def getAccuracy(testSet, predictions):\n",
        "    correct = 0\n",
        "    for x in range(len(testSet)):\n",
        "        if testSet[x][-1] == predictions[x]:\n",
        "            correct += 1\n",
        "    return (correct/float(len(testSet))) * 100.0   "
      ],
      "metadata": {
        "id": "75kdOdXL5cu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Função para carregar os dados da coluna vertebral\n",
        "def load_vertebral_column_uci():\n",
        "    # Seus dados aqui\n",
        "    data = {\n",
        "        'pelvic_incidence': [63.03, 39.06, 68.83, 69.3, 49.71],\n",
        "        'pelvic_tilt': [22.55, 10.06, 22.22, 24.65, 9.65],\n",
        "        'lumbar_lordosis_angle': [39.61, 25.02, 50.09, 44.31, 28.32],\n",
        "        'sacral_slope': [40.48, 29, 46.61, 44.64, 40.06],\n",
        "        'pelvic_radius': [98.67, 114.41, 105.99, 101.87, 108.17],\n",
        "        'degree_spondylolisthesis': [-0.25, 4.56, -3.53, 11.21, 7.92],\n",
        "        'class': ['DH', 'DH', 'DH', 'DH', 'DH']\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Carregar os dados\n",
        "vertebral_data = load_vertebral_column_uci()\n",
        "\n",
        "# Dividir os dados em features (X) e target (y)\n",
        "X = vertebral_data.drop(columns=['class'])\n",
        "y = vertebral_data['class']\n",
        "\n",
        "# Inicializar o classificador Naive Bayes Gaussiano\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Número de execuções\n",
        "num_execucoes = 20\n",
        "\n",
        "acuracias = []\n",
        "\n",
        "for _ in range(num_execucoes):\n",
        "    # Dividir os dados em conjunto de treinamento e teste\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=_)\n",
        "\n",
        "    # Treinar o classificador\n",
        "    gnb.fit(X_train, y_train)\n",
        "\n",
        "    # Fazer previsões\n",
        "    y_pred = gnb.predict(X_test)\n",
        "\n",
        "    # Calcular a acurácia\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    acuracias.append(accuracy)\n",
        "\n",
        "    # Calcular e imprimir a matriz de confusão para a última execução\n",
        "    if _ == num_execucoes - 1:\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        print(\"\\nMatriz de Confusão (última execução):\")\n",
        "        print(conf_matrix)\n",
        "\n",
        "# Calcular a acurácia média e o desvio padrão da acurácia\n",
        "acuracias = np.array(acuracias)\n",
        "acuracia_media = np.mean(acuracias)\n",
        "desvio_padrao_acuracia = np.std(acuracias)\n",
        "\n",
        "print(\"\\nAcurácia Média ({} execuções):\".format(num_execucoes), acuracia_media)\n",
        "print(\"Desvio Padrão da Acurácia ({} execuções):\".format(num_execucoes), desvio_padrao_acuracia)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hM2Ar7mxNM6",
        "outputId": "2b98eb8f-6562-4793-bff6-05a14d3d5593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz de Confusão (última execução):\n",
            "[[1]]\n",
            "\n",
            "Acurácia Média (20 execuções): 1.0\n",
            "Desvio Padrão da Acurácia (20 execuções): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from knn_dmc import KNN, DMC\n",
        "from slave import GaussianNB\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Função para carregar o conjunto de dados vertebral_column\n",
        "def load_vertebral_column_uci():\n",
        "    # URL do arquivo ZIP\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip\"\n",
        "    # Caminho local para salvar o arquivo ZIP\n",
        "    zip_path = \"vertebral_column_data.zip\"\n",
        "    # Caminho local para o arquivo de dados extraído\n",
        "    data_path = \"column_3C.dat\"\n",
        "\n",
        "    # Baixar o arquivo ZIP se ainda não foi baixado\n",
        "    if not os.path.exists(zip_path):\n",
        "        r = requests.get(url)\n",
        "        with open(zip_path, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "\n",
        "    # Extrair o arquivo de dados do ZIP se ainda não foi extraído\n",
        "    if not os.path.exists(data_path):\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "            zip_ref.extractall()\n",
        "\n",
        "    # Ler o arquivo de dados\n",
        "    column_names = ['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis', 'class']\n",
        "    vertebral_data = pd.read_csv(data_path, header=None, sep=' ', names=column_names)\n",
        "\n",
        "    # Convertendo a coluna 'class' para valores numéricos\n",
        "    class_mapping = {'DH': 0, 'SL': 1, 'NO': 2}\n",
        "    y = vertebral_data['class'].map(class_mapping).values\n",
        "    X = vertebral_data.iloc[:, :-1].values\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Função para calcular a acurácia\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "# Função para calcular a matriz de confusão\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "    classes = np.unique(y_true)\n",
        "    num_classes = len(classes)\n",
        "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    for i in range(num_classes):\n",
        "        for j in range(num_classes):\n",
        "            matrix[i, j] = np.sum((y_true == classes[i]) & (y_pred == classes[j]))\n",
        "    return matrix\n",
        "\n",
        "# Função para separar os dados em conjunto de treinamento e teste\n",
        "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
        "    if random_state:\n",
        "        np.random.seed(random_state)\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    test_samples = int(len(X) * test_size)\n",
        "    X_train = X[indices[:-test_samples]]\n",
        "    X_test = X[indices[-test_samples:]]\n",
        "    y_train = y[indices[:-test_samples]]\n",
        "    y_test = y[indices[-test_samples:]]\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Função para realizar 20 realizações de um classificador para uma base de dados\n",
        "def perform_realizations(classifier, X, y):\n",
        "    accuracies = []\n",
        "    confusion_matrices = []\n",
        "\n",
        "    for _ in range(20):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=_)\n",
        "        classifier.fit(X_train, y_train)\n",
        "        y_pred = classifier.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        accuracies.append(acc)\n",
        "        confusion_matrices.append(conf_matrix)\n",
        "\n",
        "    accuracies = np.array(accuracies)\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    std_dev_accuracy = np.std(accuracies)\n",
        "    best_realization_idx = np.argmin(np.abs(accuracies - mean_accuracy))\n",
        "    best_confusion_matrix = confusion_matrices[best_realization_idx]\n",
        "\n",
        "    return mean_accuracy, std_dev_accuracy, best_realization_idx, best_confusion_matrix\n",
        "\n",
        "\n",
        "# Função para visualizar as superfícies de decisão\n",
        "def plot_decision_surface(clf, X_train, y_train, title):\n",
        "    # Escolha dos dois primeiros atributos\n",
        "    X_train = X_train[:, :2]\n",
        "\n",
        "    # Treinar o classificador com os dois primeiros atributos\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Criação da grade de pontos\n",
        "    h = .02  # tamanho do passo na grade\n",
        "    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
        "    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predição para cada ponto na grade\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Colocando o resultado na mesma forma que a grade\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plotagem das fronteiras de decisão\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k')\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Execução da análise para o conjunto de dados vertebral_column\n",
        "print(\"\\nDataset: Vertebral Column\")\n",
        "\n",
        "X, y = load_vertebral_column_uci()\n",
        "\n",
        "knn_classifier = KNN()\n",
        "dmc_classifier = DMC()\n",
        "naive_bayes_classifier = GaussianNB()  # Este é o Naive Bayes implementado anteriormente\n",
        "\n",
        "classifiers = {\"KNN\": knn_classifier, \"DMC\": dmc_classifier, \"Naive Bayes\": naive_bayes_classifier}\n",
        "\n",
        "# Listas para armazenar os resultados de acurácia e desvio padrão\n",
        "accuracies = []\n",
        "std_devs = []\n",
        "\n",
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"\\nClassificador: {clf_name}\")\n",
        "\n",
        "    # Visualização da superfície de decisão\n",
        "    plot_decision_surface(clf, X, y, f'Vertebral Column - Decision Surface for {clf_name}')\n",
        "\n",
        "    # Realização da análise\n",
        "    mean_acc, std_dev_acc, best_realization_idx, best_conf_matrix = perform_realizations(clf, X, y)\n",
        "\n",
        "    # Impressão dos resultados\n",
        "    print(f\"Acurácia média: {mean_acc}\")\n",
        "    print(f\"Desvio padrão da acurácia: {std_dev_acc}\")\n",
        "    print(f\"Melhor realização (índice): {best_realization_idx}\")\n",
        "    print(f\"Matriz de confusão da melhor realização:\\n{best_conf_matrix}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "8sAar0872ilK",
        "outputId": "75e93dec-1317-4eb9-ee06-4eb59ece20ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ucimlrepo'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-467fb59e02a3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mknn_dmc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mslave\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/slave.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;31m#### BREAST_CANCER ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mucimlrepo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_ucirepo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;31m# fetch dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ucimlrepo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mauromelo-ti-ifce/class_ifce.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3_5u44UCSSR",
        "outputId": "a95cbe2d-bcc2-4f3d-d94d-efca2e291988"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'class_ifce'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c_4G9Bk7t3tK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OgD2_ee75X37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r4LEqw49VO3L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6lWQE2vVmjc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}